{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸš€ BDA Contest - SOTA Solution with AutoGluon\n",
                "\n",
                "## í•µì‹¬ ì „ëµ: AutoGluon (AutoML)\n",
                "- **ìµœì‹  ë…¼ë¬¸ ê¸°ìˆ  ì§‘ì•½ì²´**: Neural Network + XGBoost + LightGBM + CatBoost ìë™ ì•™ìƒë¸”\n",
                "- **Deep Learning**: ì •í˜• ë°ì´í„° ì „ìš© ì‹ ê²½ë§(Tabular Neural Network) ìë™ ì ìš©\n",
                "- **NLP í†µí•©**: í…ìŠ¤íŠ¸ ì»¬ëŸ¼(ì§€ì›ë™ê¸° ë“±)ì„ NLP ëª¨ë¸ë¡œ ì„ë² ë”©í•˜ì—¬ í™œìš©\n",
                "- **Stacking & Bagging**: ìˆ˜ì‹­ ê°œ ëª¨ë¸ì„ ê²¹ì³ ìŒ“ì•„ ê³¼ì í•© ë°©ì§€ ë° ì„±ëŠ¥ ê·¹ëŒ€í™”\n",
                "- **F1 Score ìµœì í™”**: í‰ê°€ ì§€í‘œì— ë§ì¶° í•™ìŠµ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. AutoGluon ì„¤ì¹˜ (í•„ìˆ˜)\n",
                "# ì£¼ì˜: ì„¤ì¹˜ í›„ ëŸ°íƒ€ì„ ì¬ì‹œì‘ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (RESTART SESSION ë²„íŠ¼ í´ë¦­)\n",
                "!pip install autogluon -q\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import re\n",
                "from autogluon.tabular import TabularPredictor\n",
                "\n",
                "print(\"Setup Complete! If you see errors, please Restart Session.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. ë°ì´í„° ë¡œë“œ\n",
                "RAW_TRAIN_URL = 'https://raw.githubusercontent.com/choicompany/bdadacon/refs/heads/main/rawdata/train.csv'\n",
                "RAW_TEST_URL = 'https://raw.githubusercontent.com/choicompany/bdadacon/refs/heads/main/rawdata/test.csv'\n",
                "\n",
                "train = pd.read_csv(RAW_TRAIN_URL)\n",
                "test = pd.read_csv(RAW_TEST_URL)\n",
                "\n",
                "print(f\"Train Shape: {train.shape}, Test Shape: {test.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. ìµœì†Œí•œì˜ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (í…ìŠ¤íŠ¸ëŠ” ì›ë³¸ ìœ ì§€ -> AutoGluonì´ ì½ìŒ)\n",
                "# AutoGluonì€ ì›ë³¸ ë°ì´í„°ë¥¼ ì˜ ë‹¤ë£¨ë¯€ë¡œ, ê³¼ë„í•œ ì „ì²˜ë¦¬ëŠ” ì˜¤íˆë ¤ ë…ì´ ë  ìˆ˜ ìˆìŒ.\n",
                "# í•˜ì§€ë§Œ 'ê°œìˆ˜' ì •ë³´ëŠ” ëª…ì‹œì ìœ¼ë¡œ ì£¼ëŠ” ê²ƒì´ ì¢‹ìŒ.\n",
                "\n",
                "def count_items(text):\n",
                "    if pd.isna(text) or str(text).strip() == '': return 0\n",
                "    return str(text).count(',') + 1\n",
                "\n",
                "# ë¦¬ìŠ¤íŠ¸í˜• ë°ì´í„° ê°œìˆ˜ í”¼ì²˜ ì¶”ê°€\n",
                "multi_select_cols = [\n",
                "    'certificate_acquisition', 'desired_certificate', \n",
                "    'desired_job', 'desired_job_except_data',\n",
                "    'onedayclass_topic', 'expected_domain'\n",
                "]\n",
                "\n",
                "for df in [train, test]:\n",
                "    # 1. ê°œìˆ˜ í”¼ì²˜ ìƒì„±\n",
                "    for col in multi_select_cols:\n",
                "        if col in df.columns:\n",
                "            df[f'{col}_count'] = df[col].apply(count_items)\n",
                "    \n",
                "    # 2. ì „ê³µ ë°ì´í„° íŠ¹ìˆ˜ ì²˜ë¦¬ (ì¤‘ìš”)\n",
                "    # False/True ë¬¸ìì—´ì„ 0/1ë¡œ ë³€í™˜\n",
                "    if 'major_data' in df.columns:\n",
                "        df['major_data'] = df['major_data'].astype(str).str.lower().map({'true': 1, 'false': 0}).fillna(0).astype(int)\n",
                "    \n",
                "    # 3. ë¶ˆí•„ìš” ì»¬ëŸ¼ ID ì œê±° (í•™ìŠµì—ì„œ ì œì™¸)\n",
                "    # generationì€ ì˜ë¯¸ ì—†ì–´ ë³´ì´ë‚˜ AutoGluonì´ ì•Œì•„ì„œ íŒë‹¨í•˜ê²Œ ë‘ \n",
                "\n",
                "# AutoGluonì€ Feature Engineeringì„ ë‚´ë¶€ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ë¯€ë¡œ ì—¬ê¸°ì„œ ë©ˆì¶¤.\n",
                "print(\"Feature Engineering Done.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. AutoGluon í•™ìŠµ (Highest Quality)\n",
                "# presets='best_quality' : Bagging, Stacking, Neural Network ë“± ëª¨ë“  ê¸°ìˆ  ì´ë™ì›\n",
                "# time_limit : í•™ìŠµ ì‹œê°„ ì œí•œ (ì´ˆ ë‹¨ìœ„). 600ì´ˆ(10ë¶„) ~ 1200ì´ˆ(20ë¶„) ê¶Œì¥\n",
                "\n",
                "metric = 'f1'  # F1 Score ìµœì í™”\n",
                "label = 'completed'  # íƒ€ê²Ÿ ì»¬ëŸ¼\n",
                "save_path = 'ag_models_best'  # ëª¨ë¸ ì €ì¥ ê²½ë¡œ\n",
                "\n",
                "predictor = TabularPredictor(\n",
                "    label=label,\n",
                "    eval_metric=metric,\n",
                "    path=save_path\n",
                ").fit(\n",
                "    train,\n",
                "    presets='best_quality',   # ìµœê°• ì„±ëŠ¥ ëª¨ë“œ\n",
                "    time_limit=60*10,         # 10ë¶„ ë™ì•ˆ í•™ìŠµ (Colab ë¬´ë£Œ ë²„ì „ ê³ ë ¤)\n",
                "    ag_args_fit={'num_gpus': 1} # GPU ì‚¬ìš© (Colab GPU ì¼œì ¸ ìˆì–´ì•¼ í•¨)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. ì„±ëŠ¥ í‰ê°€ (Leaderboard)\n",
                "# ì–´ë–¤ ëª¨ë¸ë“¤ì´ ë§Œë“¤ì–´ì¡Œê³  ì„±ëŠ¥ì´ ì–´ë–¤ì§€ í™•ì¸\n",
                "predictor.leaderboard(train, silent=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
                "# Test ë°ì´í„°ì—ëŠ” 'completed' ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ ì œì™¸í•˜ê³  ì˜ˆì¸¡\n",
                "\n",
                "test_data = test.drop(columns=['ID'])\n",
                "preds = predictor.predict(test_data)\n",
                "\n",
                "submission = pd.DataFrame({\n",
                "    'ID': test['ID'],\n",
                "    'completed': preds\n",
                "})\n",
                "\n",
                "submission.to_csv('submission.csv', index=False)\n",
                "print(\"Saved: submission.csv\")\n",
                "print(submission.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. ë‹¤ìš´ë¡œë“œ\n",
                "from google.colab import files\n",
                "try:\n",
                "    files.download('submission.csv')\n",
                "except:\n",
                "    print(\"ë‹¤ìš´ë¡œë“œê°€ ìë™ìœ¼ë¡œ ì‹œì‘ë˜ì§€ ì•Šìœ¼ë©´ ì™¼ìª½ íŒŒì¼ íƒ­ì—ì„œ submission.csvë¥¼ ìš°í´ë¦­í•˜ì—¬ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}