{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# BDA Contest - High Performance Model\n",
                "- 전처리 + 피처 엔지니어링 + 앙상블 모델 + F1 최적화\n",
                "- Raw Data에서 직접 불러옴"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 패키지 설치\n",
                "!pip install xgboost lightgbm catboost -q\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import re\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.metrics import f1_score\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "import xgboost as xgb\n",
                "import lightgbm as lgb\n",
                "from catboost import CatBoostClassifier\n",
                "\n",
                "SEED = 42\n",
                "np.random.seed(SEED)\n",
                "print('Setup Complete!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Raw Data 로드 (GitHub에서 직접)\n",
                "RAW_TRAIN_URL = 'https://raw.githubusercontent.com/choicompany/bdadacon/refs/heads/main/rawdata/train.csv'\n",
                "RAW_TEST_URL = 'https://raw.githubusercontent.com/choicompany/bdadacon/refs/heads/main/rawdata/test.csv'\n",
                "\n",
                "train_raw = pd.read_csv(RAW_TRAIN_URL)\n",
                "test_raw = pd.read_csv(RAW_TEST_URL)\n",
                "\n",
                "print(f'Train: {train_raw.shape}, Test: {test_raw.shape}')\n",
                "print(f\"Target: 0={sum(train_raw['completed']==0)}, 1={sum(train_raw['completed']==1)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 피처 엔지니어링 함수\n",
                "def count_items(text):\n",
                "    if pd.isna(text) or str(text).strip() == '': return 0\n",
                "    return str(text).count(',') + 1\n",
                "\n",
                "def text_length(text):\n",
                "    if pd.isna(text): return 0\n",
                "    return len(str(text))\n",
                "\n",
                "def clean_text(text):\n",
                "    if pd.isna(text): return 'Unknown'\n",
                "    return re.sub(r'[^a-zA-Z0-9가-힣]', '', str(text))\n",
                "\n",
                "# Target & IDs 분리\n",
                "y = train_raw['completed'].copy()\n",
                "test_ids = test_raw['ID'].copy()\n",
                "\n",
                "# Train/Test 합치기\n",
                "train_x = train_raw.drop(columns=['completed', 'ID'])\n",
                "test_x = test_raw.drop(columns=['ID'])\n",
                "train_x['is_train'] = 1\n",
                "test_x['is_train'] = 0\n",
                "combined = pd.concat([train_x, test_x], ignore_index=True)\n",
                "\n",
                "print('Data merged for preprocessing')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 파생 피처 생성\n",
                "print('Creating derived features...')\n",
                "\n",
                "# Null count (성실도)\n",
                "combined['null_count'] = combined.isnull().sum(axis=1)\n",
                "\n",
                "# 텍스트 길이\n",
                "for col in ['whyBDA', 'what_to_gain', 'hope_for_group', 'incumbents_lecture_scale_reason']:\n",
                "    if col in combined.columns:\n",
                "        combined[f'{col}_len'] = combined[col].apply(text_length)\n",
                "\n",
                "# 항목 개수 (콤마 기준)\n",
                "for col in ['certificate_acquisition', 'desired_certificate', 'desired_job', 'onedayclass_topic']:\n",
                "    if col in combined.columns:\n",
                "        combined[f'{col}_count'] = combined[col].apply(count_items)\n",
                "\n",
                "# 전공 관련\n",
                "combined['major_data'] = combined['major_data'].astype(str).apply(lambda x: 1 if x.lower()=='true' else 0)\n",
                "combined['is_student'] = (combined['job'] == '대학생').astype(int)\n",
                "\n",
                "# 불필요 컬럼 제거\n",
                "combined = combined.drop(columns=['generation'], errors='ignore')\n",
                "\n",
                "print('Derived features created!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 결측치 & 인코딩\n",
                "print('Encoding...')\n",
                "cat_cols = combined.select_dtypes(include=['object']).columns.tolist()\n",
                "num_cols = combined.select_dtypes(include=['number', 'bool']).columns.tolist()\n",
                "if 'is_train' in num_cols: num_cols.remove('is_train')\n",
                "\n",
                "for col in num_cols:\n",
                "    combined[col] = combined[col].fillna(-1)\n",
                "\n",
                "for col in cat_cols:\n",
                "    combined[col] = combined[col].fillna('Unknown').apply(clean_text)\n",
                "\n",
                "# High cardinality -> Label Encoding\n",
                "# Low cardinality -> One-Hot\n",
                "high_card = [c for c in cat_cols if combined[c].nunique() > 15]\n",
                "low_card = [c for c in cat_cols if combined[c].nunique() <= 15]\n",
                "\n",
                "for col in high_card:\n",
                "    le = LabelEncoder()\n",
                "    combined[col] = le.fit_transform(combined[col])\n",
                "\n",
                "if low_card:\n",
                "    combined = pd.get_dummies(combined, columns=low_card, drop_first=False, dtype=int)\n",
                "\n",
                "print(f'Encoding done! High card: {len(high_card)}, Low card: {len(low_card)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/Test 분리 & NumPy 변환\n",
                "X = combined[combined['is_train'] == 1].drop(columns=['is_train']).reset_index(drop=True)\n",
                "X_test = combined[combined['is_train'] == 0].drop(columns=['is_train']).reset_index(drop=True)\n",
                "\n",
                "# 컬럼명 정리 (XGBoost 호환)\n",
                "def clean_cols(cols):\n",
                "    seen = {}\n",
                "    result = []\n",
                "    for c in cols:\n",
                "        c = re.sub(r'[\\[\\]<>\\s]', '_', str(c))\n",
                "        if c in seen:\n",
                "            seen[c] += 1\n",
                "            result.append(f'{c}_{seen[c]}')\n",
                "        else:\n",
                "            seen[c] = 0\n",
                "            result.append(c)\n",
                "    return result\n",
                "\n",
                "X.columns = clean_cols(X.columns)\n",
                "X_test.columns = clean_cols(X_test.columns)\n",
                "\n",
                "# NumPy 변환\n",
                "X_np = X.values.astype(np.float32)\n",
                "X_test_np = X_test.values.astype(np.float32)\n",
                "y_np = y.values.astype(int)\n",
                "\n",
                "print(f'Train: {X_np.shape}, Test: {X_test_np.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 모델 학습 (OOF Ensemble)\n",
                "N_FOLDS = 5\n",
                "scale = sum(y_np == 0) / sum(y_np == 1)\n",
                "print(f'Class imbalance ratio: {scale:.2f}')\n",
                "\n",
                "def get_oof(model_class, params, X, y, X_test, n_folds=5):\n",
                "    oof = np.zeros(len(X))\n",
                "    test_preds = np.zeros(len(X_test))\n",
                "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
                "    \n",
                "    for fold, (tr_idx, val_idx) in enumerate(skf.split(X, y)):\n",
                "        model = model_class(**params)\n",
                "        model.fit(X[tr_idx], y[tr_idx])\n",
                "        oof[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n",
                "        test_preds += model.predict_proba(X_test)[:, 1] / n_folds\n",
                "    return oof, test_preds"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# XGBoost\n",
                "print('Training XGBoost...')\n",
                "xgb_oof, xgb_test = get_oof(xgb.XGBClassifier, {\n",
                "    'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05,\n",
                "    'subsample': 0.8, 'colsample_bytree': 0.8, 'scale_pos_weight': scale,\n",
                "    'random_state': SEED, 'use_label_encoder': False, 'eval_metric': 'logloss', 'n_jobs': -1\n",
                "}, X_np, y_np, X_test_np)\n",
                "print(f\"  XGBoost F1: {f1_score(y_np, (xgb_oof >= 0.5).astype(int)):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LightGBM\n",
                "print('Training LightGBM...')\n",
                "lgb_oof, lgb_test = get_oof(lgb.LGBMClassifier, {\n",
                "    'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.05,\n",
                "    'subsample': 0.8, 'colsample_bytree': 0.8, 'scale_pos_weight': scale,\n",
                "    'random_state': SEED, 'verbose': -1, 'n_jobs': -1\n",
                "}, X_np, y_np, X_test_np)\n",
                "print(f\"  LightGBM F1: {f1_score(y_np, (lgb_oof >= 0.5).astype(int)):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CatBoost\n",
                "print('Training CatBoost...')\n",
                "cat_oof, cat_test = get_oof(CatBoostClassifier, {\n",
                "    'iterations': 500, 'depth': 5, 'learning_rate': 0.05,\n",
                "    'random_seed': SEED, 'verbose': 0, 'class_weights': {0: 1, 1: scale}\n",
                "}, X_np, y_np, X_test_np)\n",
                "print(f\"  CatBoost F1: {f1_score(y_np, (cat_oof >= 0.5).astype(int)):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 앙상블 (Stacking)\n",
                "oof_stack = np.column_stack([xgb_oof, lgb_oof, cat_oof])\n",
                "test_stack = np.column_stack([xgb_test, lgb_test, cat_test])\n",
                "\n",
                "# Meta model\n",
                "meta = LogisticRegression(random_state=SEED, max_iter=1000)\n",
                "meta.fit(oof_stack, y_np)\n",
                "\n",
                "final_oof = meta.predict_proba(oof_stack)[:, 1]\n",
                "final_test_probs = meta.predict_proba(test_stack)[:, 1]\n",
                "\n",
                "print(f'Meta weights: {meta.coef_[0]}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Threshold 최적화 (F1 Score 기준)\n",
                "best_f1, best_th = 0, 0.5\n",
                "for th in np.arange(0.2, 0.8, 0.01):\n",
                "    f1 = f1_score(y_np, (final_oof >= th).astype(int))\n",
                "    if f1 > best_f1:\n",
                "        best_f1, best_th = f1, th\n",
                "\n",
                "print(f'Best Threshold: {best_th:.2f}')\n",
                "print(f'Best OOF F1: {best_f1:.4f}')\n",
                "\n",
                "# 최종 예측\n",
                "final_preds = (final_test_probs >= best_th).astype(int)\n",
                "print(f'Predicted 0: {sum(final_preds==0)}, 1: {sum(final_preds==1)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 제출 파일 생성\n",
                "submission = pd.DataFrame({'ID': test_ids, 'completed': final_preds})\n",
                "submission.to_csv('submission.csv', index=False)\n",
                "print('Saved: submission.csv')\n",
                "print(submission.head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Colab 다운로드\n",
                "from google.colab import files\n",
                "files.download('submission.csv')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}