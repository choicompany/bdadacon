
# 데이터 전처리 전략 리포트

## 1. 개요
Boosting 모델(XGBoost, LightGBM 등) 성능 극대화를 위한 맞춤형 전처리 로직 설명.
복잡한 설명 없이 **"어떻게 바꿨는지"** 예시 위주로 기술함.

## 2. 서술형 데이터 처리 (핵심)
질문: *"서술형 데이터를 어떻게 처리했는가?"*

### A. 같은 문장은 같은 숫자로 (Label Encoding)
서술형 답변이라도 주관식 단답형처럼 **똑같이 쓴 답변끼리 묶어서** 숫자로 변환함. Boosting 모델은 이 숫자를 보고 "아, 3번 답변(=혼자 하기 어려워서)을 한 사람들은 합격률이 높구나"라고 학습함.

- **예시 (`whyBDA` 컬럼)**
    - "혼자 공부하기 어려워서" → **3**
    - "커리큘럼이 좋아서" → **7**
    - "지인 추천" → **1**

### B. 답변 길이 변수 추가 (Text Length)
내용을 떠나서 **"얼마나 길게 썼는지"** 그 정성 자체가 중요한 정보가 됨.
- **예시**
    - "혼자 공부하기 어려워서" (13글자) → `whyBDA_len`: **13**
    - "데이터 분석 역량을 키우고 싶고, ... (중략) ... 해서 지원했습니다" (50글자) → `whyBDA_len`: **50**
    *→ 결과적으로 모델은 내용(3번 카테고리)과 정성(글자 수 13) 두 가지 정보를 모두 활용하게 됨.*

## 3. 범주형 변수 인코딩 (Hybrid 방식)
질문: *"그냥 원핫인코딩(One-Hot) 써도 되나?"*
답변: **반은 맞고 반은 틀림.** 항목이 너무 많은 변수를 원핫으로 만들면 모델이 멍청해짐(Data sparsity). 그래서 섞어 씀.

### A. 항목이 적을 때 (15개 미만) → 원핫 인코딩 (One-Hot)
항목이 몇 개 없으면 펼치는 게 정보 손실이 적고 좋음.
- **예시 (`contest_award` - 공모전 수상 여부)**
    - 없다 / 있다 (2개)
    - → `contest_award_0`, `contest_award_1` 컬럼으로 쪼개서 0 또는 1로 표시.

### B. 항목이 많을 때 (15개 이상) → 라벨 인코딩 (Label)
항목이 수십 개인 변수를 원핫으로 하면 컬럼이 수백 개로 늘어나서 학습이 느려지고 성능 떨어짐. 그냥 숫자로 바꿈.
- **예시 (`school1` - 학교 코드)**
    - 학교가 100개면 원핫 인코딩 시 컬럼 100개 생성됨 (비효율).
    - 그냥 학교 A는 **1**, 학교 B는 **2**... 로 변환. 트리기반 모델은 이걸 잘 처리함.

## 4. 결측치(빈칸) 처리
- **숫자 데이터**: **중앙값(Median)** 채움. 평균은 이상한 값(튀는 값)에 영향을 많이 받아서 안 씀.
- **문자 데이터**: **'Unknown'**이라는 글자로 채움. "비워둔 것" 자체도 하나의 정보로 활용.

## 5. 요약
1. 쓸모없는 `ID`, `기수(generation)` 삭제.
2. 서술형은 **내용(숫자변환) + 길이(글자수)** 2개 변수로 쪼개서 넣음.
3. 항목 적으면 **원핫**, 항목 많으면 **라벨** 인코딩 섞어서 씀.
